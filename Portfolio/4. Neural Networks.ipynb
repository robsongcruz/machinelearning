{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='stats/img/topbar.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CONTEÚDO:__<br>\n",
    "* [1. Neural Networks](#1.)\n",
    "* [1.1 Arquiteturas de Redes Neurais](#1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0.\"></a><br>\n",
    "### 1. Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encadeamento de pequenas unidades, comumente chamadas de neurônios, responsáveis por absorver parte das características de um elemento de entrada.\n",
    "- Podem ser usadas em Regressão, Classificação e muito mais aplicações.\n",
    "- Geralmente trabalham melhor com parâmetros padronizados/normalizados.\n",
    "- [Diferença entre NN e Deep?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='stats/img/neural.png' width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a><br>\n",
    "### 1.1 Arquiteturas de Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='stats/img/NN.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The universal workflow (Livro: *Deep Learning with Python*, François Chollet - 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Definir o problema e montar o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What will your input data be? What are you trying to predict?\n",
    "- What type of problem are you facing? Is it binary classification? Multiclass classification? Scalar regression? Vector regression? Multiclass, multilabel classification? Something else, like clustering, generation, or reinforcement learning? Identifying the problem type will guide your choice of model architecture, loss function, and so on.\n",
    "- Hypothesis:   \n",
    "        a) your outputs can be predicted given your inputs.\n",
    "        b) your available data is sufficiently informative to learn the relationship between inputs and outputs.\n",
    "- Keep in mind that machine learning can only be used to memorize patterns that are present in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Escolher uma métrica de sucesso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy? Precision and recall? Customer-retention rate? Your metric for success will guide the choice of a loss function: what your model will optimize.\n",
    "- For balanced-classification problems, where every class is equally likely, accuracy and area under the receiver operating characteristic curve (ROC AUC) are common metrics. For class-imbalanced problems, you can use precision and recall. For ranking problems or multilabel classification, you can use mean average precision. And it isn’t uncommon to have to define your own custom metric by which to measure success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Definir um protocolo de avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maintaining a hold-out validation set: The way to go when you have plenty of data.\n",
    "- Doing K-fold cross-validation: The right choice when you have too few samples for hold-out validation to be reliable.\n",
    "- Doing iterated K-fold validation: For performing highly accurate model evaluation when little data is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Adequar os dados para a rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data should be formatted as tensors.\n",
    "- The values taken by these tensors should usually be scaled to small values: for example, in the [-1, 1] range or [0, 1] range.\n",
    "- If different features take values in different ranges (heterogeneous data), then the data should be normalized.\n",
    "- You may want to do some feature engineering, especially for small-data problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5 Desenvolver um modelo base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss functions, after all, need to be computable given only a mini-batch of data (ideally, a loss function should be computable for as little as a single data point) and must be differentiable (otherwise, you can’t use backpropagation to train your network).\n",
    "- In general, you can hope that the lower the crossentropy gets, the higher the ROC AUC will be.\n",
    "\n",
    "|  Tipo de Problema  |  Camada de Ativação  |  Loss function  |\n",
    "|---|---|---|\n",
    "|  Classificação Binária  |  Sigmoid  |  binary_crossentropy  |\n",
    "|  Classificação multiclasses, instância com classe única  |  Softmax  | categorical_crossentropy  |\n",
    "|  Classificação multiclasses, instância multiclasses  |  Sigmoid  | binary_crossentropy  |\n",
    "|  Regressão para valores arbitrários  |  (Sem função de ativação)  |  mse  |\n",
    "|  Regressão para valores entre 0 e 1  |  Sigmoid  |  mse ou binary_crossentropy  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.6 Desenvolver um modelo com overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) Add layers.\n",
    "- 2) Make the layers bigger.\n",
    "- 3) Train for more epochs. <br><br>\n",
    "- Remember that the universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
    "- Always monitor the training loss and validation loss, as well as the training and validation values for any metrics you care about. When you see that the model’s performance on the validation data begins to degrade, you’ve achieved overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.7 Regularizar e sintonizar hiperparâmetros do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) Add dropout.\n",
    "- 2) Try different architectures: add or remove layers.\n",
    "- 3) Add L1 and/or L2 regularization.\n",
    "- 4) Try different hyperparameters (such as the number of units per layer or the learning rate of the optimizer) to find the optimal configuration.\n",
    "- 5) Optionally, iterate on feature engineering: add new features, or remove features that don’t seem to be informative.\n",
    "- 6) Repeat 1-5 styeps until the model is as good as it can get."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
