{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Python Fundamentos - Capítulo 6</font>\n",
    "\n",
    "## Download: http://github.com/dsacademybr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.7.4\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream de Dados do Twitter com MongoDB, Pandas e Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando a Conexão com o Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.11.1 in d:\\programs\\anaconda3\\lib\\site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\dovahkiin\\appdata\\roaming\\python\\python37\\site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in d:\\programs\\anaconda3\\lib\\site-packages (from tweepy) (1.7.1)\n",
      "Collecting requests-oauthlib>=0.7.0 (from tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\programs\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\programs\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\programs\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.1.0 requests-oauthlib-1.3.0 tweepy-3.8.0\n"
     ]
    }
   ],
   "source": [
    "# Instala o pacote tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos Tweepy, Datetime e Json\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja no manual em pdf como criar sua API no Twitter e configure as suas chaves abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = open('./twitter_token.txt')\n",
    "tkn = json.load(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api-key': 'o2nJC5zaumfTYPfZUmNW0DN5J', 'api-secret-key': 'bWXoXUfNFtWRCHqiYEIDQRgDlzNTh21ZcXRaYdUj9TCQr9Egpz', 'access-token': '953111285276860419-a1oEYtwt7wtH6V4v172Bti1cdg9D0u8', 'access-secret-token': 'VtHk1wxhb8EIuyxC4c3L639nA9tvT2E3qsiKz9pLCpLed'}\n"
     ]
    }
   ],
   "source": [
    "print(tkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui sua Consumer Key\n",
    "consumer_key = tkn['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui sua Consumer Secret \n",
    "consumer_secret = tkn['api-secret-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui seu Access Token\n",
    "access_token = tkn['access-token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui seu Access Token Secret\n",
    "access_token_secret = tkn['access-secret-token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as chaves de autenticação\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma classe para capturar os stream de dados do Twitter e \n",
    "# armazenar no MongoDB\n",
    "class MyListener(StreamListener):\n",
    "    def on_data(self, dados):\n",
    "        tweet = json.loads(dados)\n",
    "        created_at = tweet[\"created_at\"]\n",
    "        id_str = tweet[\"id_str\"]\n",
    "        text = tweet[\"text\"]\n",
    "        obj = {\"created_at\":created_at,\"id_str\":id_str,\"text\":text,}\n",
    "        tweetind = col.insert_one(obj).inserted_id\n",
    "        print (obj)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto mylistener\n",
    "mylistener = MyListener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto mystream\n",
    "mystream = Stream(auth, listener = mylistener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando a Conexão com o MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando do PyMongo o módulo MongoClient\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a conexão ao MongoDB\n",
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o banco de dados twitterdb\n",
    "db = client.twitterdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a collection \"col\"\n",
    "col = db.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista de palavras chave para buscar nos Tweets\n",
    "keywords = ['Big Data', 'Python', 'Data Mining', 'Data Science']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando os Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Fri Apr 10 01:10:31 +0000 2020', 'id_str': '1248418044788932611', 'text': 'RT @antgrasso: Quantum science could have significant implications for national security. By taking simple, pragmatic steps today, governme…', '_id': ObjectId('5e8fc78dcbe4276d2721464b')}\n",
      "{'created_at': 'Fri Apr 10 01:10:32 +0000 2020', 'id_str': '1248418051751415810', 'text': 'Data Science -Project Leader – The Aerospace Corporation – El Segundo, CA https://t.co/0Uyy9k2nYL #secureaspects', '_id': ObjectId('5e8fc78ecbe4276d2721464c')}\n",
      "{'created_at': 'Fri Apr 10 01:10:49 +0000 2020', 'id_str': '1248418123461439492', 'text': \"You can dislike firearms or The Post Millenial as much as you want, but you can't ignore the data from StatsCan and… https://t.co/sKctwURW2Y\", '_id': ObjectId('5e8fc79fcbe4276d2721464d')}\n",
      "{'created_at': 'Fri Apr 10 01:10:58 +0000 2020', 'id_str': '1248418162107801604', 'text': 'RT @MJA_Editor: Agree. And publish it. Australia’s leading scientists call for data underpinning COVID-19 decisions to be made public | Aus…', '_id': ObjectId('5e8fc7a9cbe4276d2721464e')}\n",
      "{'created_at': 'Fri Apr 10 01:10:59 +0000 2020', 'id_str': '1248418165744209921', 'text': '@realDonaldTrump stop taking advice from Bill Gates\\nPlease have an independent counsel impaneled to investigate vac… https://t.co/Xy7UgjSv43', '_id': ObjectId('5e8fc7a9cbe4276d2721464f')}\n",
      "{'created_at': 'Fri Apr 10 01:11:05 +0000 2020', 'id_str': '1248418189265924114', 'text': 'Ignore Errors when Reading Wifis on macOS https://t.co/aSU3Zl2r2b #github #Python #Makefile #Shell #Ruby', '_id': ObjectId('5e8fc7afcbe4276d27214650')}\n",
      "{'created_at': 'Fri Apr 10 01:11:06 +0000 2020', 'id_str': '1248418191560159239', 'text': 'Sick python burn. “I would hate to be a bank and have Python, and Python 3 came out and broke everything, and then… https://t.co/HXBbqX0XqS', '_id': ObjectId('5e8fc7b0cbe4276d27214651')}\n",
      "{'created_at': 'Fri Apr 10 01:11:13 +0000 2020', 'id_str': '1248418221713022977', 'text': 'Programando em Python e bate aquela saudade do debug do abap', '_id': ObjectId('5e8fc7b7cbe4276d27214652')}\n",
      "{'created_at': 'Fri Apr 10 01:11:13 +0000 2020', 'id_str': '1248418223088742402', 'text': 'RT @Cris_noticias: Según data preliminar un tratamiento israelí contra el coronavirus prueba 100 % de supervivencia. No sólo sobrevivieron…', '_id': ObjectId('5e8fc7b7cbe4276d27214653')}\n",
      "{'created_at': 'Fri Apr 10 01:11:17 +0000 2020', 'id_str': '1248418240428007433', 'text': \"RT @couponfree01: Udemy Free Discount - Webpack 2: The Complete Developer's Guide #udemycoupon https://t.co/1tFDdJiqZl\\n\\n#webdevelopment #ja…\", '_id': ObjectId('5e8fc7bbcbe4276d27214654')}\n",
      "{'created_at': 'Fri Apr 10 01:11:22 +0000 2020', 'id_str': '1248418258622926848', 'text': 'RT @fb_vinid: Our new paper is finally online (with @TerragniSilvia and @dirk_hovy). Increase the topic coherence of your neural variationa…', '_id': ObjectId('5e8fc7bfcbe4276d27214655')}\n",
      "{'created_at': 'Fri Apr 10 01:11:22 +0000 2020', 'id_str': '1248418258899718146', 'text': 'RT @arteagamassieu: Israeli COVID-19 treatment shows 100% survival rate - preliminary data - The Jerusalem Post https://t.co/rLYT52aZMl', '_id': ObjectId('5e8fc7c0cbe4276d27214656')}\n",
      "{'created_at': 'Fri Apr 10 01:11:23 +0000 2020', 'id_str': '1248418262968221703', 'text': '@ALT_uscis Data and science will eventually carry the day', '_id': ObjectId('5e8fc7c1cbe4276d27214657')}\n",
      "{'created_at': 'Fri Apr 10 01:11:25 +0000 2020', 'id_str': '1248418273797869569', 'text': 'RT @StevenKirchner: Open Data Science Conference #DeepLearning #learning #machinelearning via https://t.co/cWtH1dD3sA https://t.co/Bc9xdVvJ…', '_id': ObjectId('5e8fc7c3cbe4276d27214658')}\n",
      "{'created_at': 'Fri Apr 10 01:11:29 +0000 2020', 'id_str': '1248418291774701569', 'text': 'RT @Berkarya_Info: Kuatkan ketahanan pangan, jauhi desa digital (sasaran ekspansi kapitalis berbekal big data).  Produksi barang yang tidak…', '_id': ObjectId('5e8fc7c7cbe4276d27214659')}\n",
      "{'created_at': 'Fri Apr 10 01:11:47 +0000 2020', 'id_str': '1248418366269734921', 'text': 'RT @adlightner: Deciding to leave earlier than planned was difficult, esp when in the field trying to forecast if #covid19 \"might become\" p…', '_id': ObjectId('5e8fc7d9cbe4276d2721465a')}\n",
      "{'created_at': 'Fri Apr 10 01:11:50 +0000 2020', 'id_str': '1248418377619533824', 'text': \"RT @pyGEDI: pyGEDI: New Python Package for analyzing @GEDI_Knights data from NASA's Global Ecosystem Dynamics Investigation.\\n\\nhttps://t.co/…\", '_id': ObjectId('5e8fc7dccbe4276d2721465b')}\n",
      "{'created_at': 'Fri Apr 10 01:11:53 +0000 2020', 'id_str': '1248418390156259334', 'text': \"@dailyremarx Yes, I often wish I still had an ArcGIS license. I didn't get deep enough to need to know Python/SQL/R… https://t.co/b0up7UeyaN\", '_id': ObjectId('5e8fc7dfcbe4276d2721465c')}\n",
      "{'created_at': 'Fri Apr 10 01:11:55 +0000 2020', 'id_str': '1248418400163880961', 'text': 'RT @treehouse: Enroll in Techdegree: https://t.co/MXgvBSRUpi\\n\\nGet an affordable online education in: \\n🌱 Full Stack JavaScript\\n🌱 Front End W…', '_id': ObjectId('5e8fc7e1cbe4276d2721465d')}\n",
      "{'created_at': 'Fri Apr 10 01:11:55 +0000 2020', 'id_str': '1248418400587509762', 'text': 'RT @Berkarya_Info: Kuatkan ketahanan pangan, jauhi desa digital (sasaran ekspansi kapitalis berbekal big data).  Produksi barang yang tidak…', '_id': ObjectId('5e8fc7e1cbe4276d2721465e')}\n",
      "{'created_at': 'Fri Apr 10 01:11:58 +0000 2020', 'id_str': '1248418412855824384', 'text': \"It's called Science.........You start with a theory and you prove, disprove, or modify your theory as you do your r… https://t.co/JjeDR6Rqkf\", '_id': ObjectId('5e8fc7e4cbe4276d2721465f')}\n",
      "{'created_at': 'Fri Apr 10 01:12:01 +0000 2020', 'id_str': '1248418425958838279', 'text': '@Ana_Squared Love me some Python :) Packaging is definitely an unsolved problem for the uninitiated.', '_id': ObjectId('5e8fc7e7cbe4276d27214660')}\n",
      "{'created_at': 'Fri Apr 10 01:12:09 +0000 2020', 'id_str': '1248418456367534080', 'text': 'scikit-learn Cookbook - Second Edition: Over 80 recipes for machine learning in Python with scikit-learn… https://t.co/YOsReTGDsJ', '_id': ObjectId('5e8fc7efcbe4276d27214661')}\n",
      "{'created_at': 'Fri Apr 10 01:12:09 +0000 2020', 'id_str': '1248418458666065920', 'text': 'The Python Language Reference: Release 3.6.4 https://t.co/A5XXmqk3k5  #python #ad', '_id': ObjectId('5e8fc7efcbe4276d27214662')}\n",
      "{'created_at': 'Fri Apr 10 01:12:11 +0000 2020', 'id_str': '1248418466324860929', 'text': 'RT @DD_FaFa_: R for Data Science: Import, Tidy, Transform, Visualize, and Model Data https://t.co/CTNQNjP8M9 #DataScience', '_id': ObjectId('5e8fc7f1cbe4276d27214663')}\n",
      "{'created_at': 'Fri Apr 10 01:12:14 +0000 2020', 'id_str': '1248418477318131714', 'text': 'RT @GIS_DOG: @DThompsonDev Have to get my friend @GinoPronos some motivation!  He’s learning how to code in python and C right now in a #Li…', '_id': ObjectId('5e8fc7f4cbe4276d27214664')}\n",
      "{'created_at': 'Fri Apr 10 01:12:16 +0000 2020', 'id_str': '1248418485257953281', 'text': '@reddeerlee This might be a good time for City if Red Deer to work on an economic renewal plan with businesses. Sta… https://t.co/I2nrl05m0T', '_id': ObjectId('5e8fc7f6cbe4276d27214665')}\n",
      "{'created_at': 'Fri Apr 10 01:12:16 +0000 2020', 'id_str': '1248418486176497664', 'text': \"'The U.S.reiterates the need for complete transparency, timely sharing of public health data, information. The most… https://t.co/onx70OVlIx\", '_id': ObjectId('5e8fc7f6cbe4276d27214666')}\n",
      "{'created_at': 'Fri Apr 10 01:12:23 +0000 2020', 'id_str': '1248418515322687490', 'text': 'RT @GIS_DOG: @DThompsonDev Have to get my friend @GinoPronos some motivation!  He’s learning how to code in python and C right now in a #Li…', '_id': ObjectId('5e8fc7fdcbe4276d27214667')}\n",
      "{'created_at': 'Fri Apr 10 01:12:28 +0000 2020', 'id_str': '1248418539456720898', 'text': 'RT @srmduke87: @ALT_uscis Data and science will eventually carry the day', '_id': ObjectId('5e8fc802cbe4276d27214668')}\n",
      "{'created_at': 'Fri Apr 10 01:12:31 +0000 2020', 'id_str': '1248418549111984130', 'text': '全てはpythonで型チェックできないのが元凶なんだよな', '_id': ObjectId('5e8fc805cbe4276d27214669')}\n",
      "{'created_at': 'Fri Apr 10 01:12:31 +0000 2020', 'id_str': '1248418549757968390', 'text': \"RT @pyGEDI: pyGEDI: New Python Package for analyzing @GEDI_Knights data from NASA's Global Ecosystem Dynamics Investigation.\\n\\nhttps://t.co/…\", '_id': ObjectId('5e8fc805cbe4276d2721466a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Fri Apr 10 01:12:37 +0000 2020', 'id_str': '1248418573959041029', 'text': \"RT @couponfree01: Udemy Free Discount - Webpack 2: The Complete Developer's Guide #udemycoupon https://t.co/1tFDdJiqZl\\n\\n#webdevelopment #ja…\", '_id': ObjectId('5e8fc80bcbe4276d2721466b')}\n",
      "{'created_at': 'Fri Apr 10 01:12:38 +0000 2020', 'id_str': '1248418579562680324', 'text': 'RT @juliecollins123: Evet sayın müminler, biliyorum bizi günahınız kadar sevmezsiniz ama maalesef çözüm yine #Israel’den geliyor..😃😃🇮🇱🇮🇱🇮🇱', '_id': ObjectId('5e8fc80ccbe4276d2721466c')}\n",
      "{'created_at': 'Fri Apr 10 01:12:39 +0000 2020', 'id_str': '1248418584478375937', 'text': 'RT @antgrasso: Quantum science could have significant implications for national security. By taking simple, pragmatic steps today, governme…', '_id': ObjectId('5e8fc80dcbe4276d2721466d')}\n",
      "{'created_at': 'Fri Apr 10 01:12:52 +0000 2020', 'id_str': '1248418636584218625', 'text': \"RT @ResistanceRules: Porter's report shows the Trump administration was not simply ill-prepared for the coming pandemic, but actively makin…\", '_id': ObjectId('5e8fc81acbe4276d2721466e')}\n",
      "{'created_at': 'Fri Apr 10 01:12:57 +0000 2020', 'id_str': '1248418659426373637', 'text': 'RT @gp_pulipaka: Cheat Sheets: #Python, #DataScience, R, and More. #BigData #Analytics #IoT #IIoT #PyTorch #RStats #TensorFlow #JavaScript…', '_id': ObjectId('5e8fc81fcbe4276d2721466f')}\n",
      "{'created_at': 'Fri Apr 10 01:12:57 +0000 2020', 'id_str': '1248418660034600960', 'text': 'RT @DataCamp: Staying Home More? Why not learn a new skill and boost your career. \\nTry Our Free Intro to SQL, Today!  Learn by doing intera…', '_id': ObjectId('5e8fc81fcbe4276d27214670')}\n",
      "{'created_at': 'Fri Apr 10 01:12:57 +0000 2020', 'id_str': '1248418660655349760', 'text': 'RT @GrimmGreen: how do we have to state AGs @MassAGO and @AGIowa with such DRASTICALLY differing views on #Vaping ?  Do they not have acces…', '_id': ObjectId('5e8fc81fcbe4276d27214671')}\n",
      "{'created_at': 'Fri Apr 10 01:12:59 +0000 2020', 'id_str': '1248418666581905416', 'text': 'Using Data Science to Advance Educational Tools for Young Children: Fifth Annual Data Science Bowl Announces Winner… https://t.co/5Zn3ZeUpym', '_id': ObjectId('5e8fc821cbe4276d27214672')}\n",
      "{'created_at': 'Fri Apr 10 01:13:00 +0000 2020', 'id_str': '1248418672386830336', 'text': 'RT @zeldia123: Learn these mini tricks to spice up your #python #data analysis🎩\\n🦄Combine least frequent categories\\n🐥Zip to iterate list ele…', '_id': ObjectId('5e8fc822cbe4276d27214673')}\n",
      "{'created_at': 'Fri Apr 10 01:13:05 +0000 2020', 'id_str': '1248418694637572098', 'text': 'RT @zeldia123: Learn these mini tricks to spice up your #python #data analysis🎩\\n🦄Combine least frequent categories\\n🐥Zip to iterate list ele…', '_id': ObjectId('5e8fc827cbe4276d27214674')}\n",
      "{'created_at': 'Fri Apr 10 01:13:06 +0000 2020', 'id_str': '1248418695744876544', 'text': 'Nas dúvidas do layout ainda.. mas vai sair o fute filosofico do MONTY PYTHON.\\n\\n#futeboldebotao https://t.co/8R5ChVvT9a', '_id': ObjectId('5e8fc828cbe4276d27214675')}\n",
      "{'created_at': 'Fri Apr 10 01:13:11 +0000 2020', 'id_str': '1248418716015931393', 'text': '@diabovestepraga eu peguei um\\nvi metade a um tempinho \\nmas devo largar pq vou largar python pra ver js e java(só vo… https://t.co/mz62cyTGhy', '_id': ObjectId('5e8fc82dcbe4276d27214676')}\n",
      "{'created_at': 'Fri Apr 10 01:13:15 +0000 2020', 'id_str': '1248418734898728960', 'text': 'For those taking part in #30DaysOfPython, I hope you had fun tackling the credit card validator project!\\n\\nOver the… https://t.co/MDK7mNHYEv', '_id': ObjectId('5e8fc831cbe4276d27214677')}\n",
      "{'created_at': 'Fri Apr 10 01:13:27 +0000 2020', 'id_str': '1248418783087083529', 'text': 'RT @zeldia123: Learn these mini tricks to spice up your #python #data analysis🎩\\n🦄Combine least frequent categories\\n🐥Zip to iterate list ele…', '_id': ObjectId('5e8fc83dcbe4276d27214678')}\n",
      "{'created_at': 'Fri Apr 10 01:13:29 +0000 2020', 'id_str': '1248418792645881857', 'text': 'RT @ProfessorAMuse: A whispered hero &amp; call to action is connecting us to navigate thru &amp; after #COVIDー19 \\n\\n\\U0001fa7aTele-medicine\\n📚Tele-education…', '_id': ObjectId('5e8fc83fcbe4276d27214679')}\n",
      "{'created_at': 'Fri Apr 10 01:13:30 +0000 2020', 'id_str': '1248418797733568512', 'text': 'Solo he visto la mitad!! 😮📺 📼 \\nTop 20 movies about Artificial Intelligence and Big Data. by @benthecoder1 in… https://t.co/zqsYfAsqqE', '_id': ObjectId('5e8fc840cbe4276d2721467a')}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1821\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1622\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1623\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-6a9070444200>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Iniciando o filtro e gravando os tweets no MongoDB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmystream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0mstripped_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mline\u001b[0m \u001b[1;31m# line is sometimes None so we need to check here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstripped_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[1;34m(self, sep)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Close the connection when no data is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    552\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;31m# Read the next chunk size from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunk size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The read operation timed out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[1;34m(sock, timeout)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msocket\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0mexpired\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \"\"\"\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwait_for_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36mselect_wait_for_socket\u001b[1;34m(sock, read, write, timeout)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m# thing.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwcheck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mrready\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwready\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrready\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwready\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mxready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36m_retry_on_intr\u001b[1;34m(fn, timeout)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Modern Python, that retries syscalls by default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Old and broken Pythons.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iniciando o filtro e gravando os tweets no MongoDB\n",
    "mystream.filter(track=keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> Pressione o botão Stop na barra de ferramentas para encerrar a captura dos Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultando os Dados no MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystream.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5e8fb663cbe4276d27214648'),\n",
       " 'created_at': 'Thu Apr 09 23:57:17 +0000 2020',\n",
       " 'id_str': '1248399615583346695',\n",
       " 'text': '@DrSCoffin perpetuated recently by the big journals as a scare tactic to stop the proposals by members of the EPA t… https://t.co/UaoYfLvrkK'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando um documento no collection\n",
    "col.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Dados com Pandas e Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'created_at': 'Thu Apr 09 23:57:17 +0000 2020',\n",
       "  'text': '@DrSCoffin perpetuated recently by the big journals as a scare tactic to stop the proposals by members of the EPA t… https://t.co/UaoYfLvrkK'},\n",
       " {'created_at': 'Thu Apr 09 23:57:18 +0000 2020',\n",
       "  'text': 'RT @gp_pulipaka: #TensorFlow 2.0 and #AI Make it Easy to Maintain and Sustain #MachineLearning. #BigData #Analytics #DataScience #IoT #IIoT…'},\n",
       " {'created_at': 'Thu Apr 09 23:57:18 +0000 2020',\n",
       "  'text': '@Tzefira_Neviah Python is a great start'},\n",
       " {'created_at': 'Fri Apr 10 01:10:31 +0000 2020',\n",
       "  'text': 'RT @antgrasso: Quantum science could have significant implications for national security. By taking simple, pragmatic steps today, governme…'},\n",
       " {'created_at': 'Fri Apr 10 01:10:32 +0000 2020',\n",
       "  'text': 'Data Science -Project Leader – The Aerospace Corporation – El Segundo, CA https://t.co/0Uyy9k2nYL #secureaspects'},\n",
       " {'created_at': 'Fri Apr 10 01:10:49 +0000 2020',\n",
       "  'text': \"You can dislike firearms or The Post Millenial as much as you want, but you can't ignore the data from StatsCan and… https://t.co/sKctwURW2Y\"},\n",
       " {'created_at': 'Fri Apr 10 01:10:58 +0000 2020',\n",
       "  'text': 'RT @MJA_Editor: Agree. And publish it. Australia’s leading scientists call for data underpinning COVID-19 decisions to be made public | Aus…'},\n",
       " {'created_at': 'Fri Apr 10 01:10:59 +0000 2020',\n",
       "  'text': '@realDonaldTrump stop taking advice from Bill Gates\\nPlease have an independent counsel impaneled to investigate vac… https://t.co/Xy7UgjSv43'},\n",
       " {'created_at': 'Fri Apr 10 01:11:05 +0000 2020',\n",
       "  'text': 'Ignore Errors when Reading Wifis on macOS https://t.co/aSU3Zl2r2b #github #Python #Makefile #Shell #Ruby'},\n",
       " {'created_at': 'Fri Apr 10 01:11:06 +0000 2020',\n",
       "  'text': 'Sick python burn. “I would hate to be a bank and have Python, and Python 3 came out and broke everything, and then… https://t.co/HXBbqX0XqS'},\n",
       " {'created_at': 'Fri Apr 10 01:11:13 +0000 2020',\n",
       "  'text': 'Programando em Python e bate aquela saudade do debug do abap'},\n",
       " {'created_at': 'Fri Apr 10 01:11:13 +0000 2020',\n",
       "  'text': 'RT @Cris_noticias: Según data preliminar un tratamiento israelí contra el coronavirus prueba 100 % de supervivencia. No sólo sobrevivieron…'},\n",
       " {'created_at': 'Fri Apr 10 01:11:17 +0000 2020',\n",
       "  'text': \"RT @couponfree01: Udemy Free Discount - Webpack 2: The Complete Developer's Guide #udemycoupon https://t.co/1tFDdJiqZl\\n\\n#webdevelopment #ja…\"},\n",
       " {'created_at': 'Fri Apr 10 01:11:22 +0000 2020',\n",
       "  'text': 'RT @fb_vinid: Our new paper is finally online (with @TerragniSilvia and @dirk_hovy). Increase the topic coherence of your neural variationa…'},\n",
       " {'created_at': 'Fri Apr 10 01:11:22 +0000 2020',\n",
       "  'text': 'RT @arteagamassieu: Israeli COVID-19 treatment shows 100% survival rate - preliminary data - The Jerusalem Post https://t.co/rLYT52aZMl'},\n",
       " {'created_at': 'Fri Apr 10 01:11:23 +0000 2020',\n",
       "  'text': '@ALT_uscis Data and science will eventually carry the day'},\n",
       " {'created_at': 'Fri Apr 10 01:11:25 +0000 2020',\n",
       "  'text': 'RT @StevenKirchner: Open Data Science Conference #DeepLearning #learning #machinelearning via https://t.co/cWtH1dD3sA https://t.co/Bc9xdVvJ…'},\n",
       " {'created_at': 'Fri Apr 10 01:11:29 +0000 2020',\n",
       "  'text': 'RT @Berkarya_Info: Kuatkan ketahanan pangan, jauhi desa digital (sasaran ekspansi kapitalis berbekal big data).  Produksi barang yang tidak…'},\n",
       " {'created_at': 'Fri Apr 10 01:11:47 +0000 2020',\n",
       "  'text': 'RT @adlightner: Deciding to leave earlier than planned was difficult, esp when in the field trying to forecast if #covid19 \"might become\" p…'},\n",
       " {'created_at': 'Fri Apr 10 01:11:50 +0000 2020',\n",
       "  'text': \"RT @pyGEDI: pyGEDI: New Python Package for analyzing @GEDI_Knights data from NASA's Global Ecosystem Dynamics Investigation.\\n\\nhttps://t.co/…\"},\n",
       " {'created_at': 'Fri Apr 10 01:11:53 +0000 2020',\n",
       "  'text': \"@dailyremarx Yes, I often wish I still had an ArcGIS license. I didn't get deep enough to need to know Python/SQL/R… https://t.co/b0up7UeyaN\"},\n",
       " {'created_at': 'Fri Apr 10 01:11:55 +0000 2020',\n",
       "  'text': 'RT @treehouse: Enroll in Techdegree: https://t.co/MXgvBSRUpi\\n\\nGet an affordable online education in: \\n🌱 Full Stack JavaScript\\n🌱 Front End W…'},\n",
       " {'created_at': 'Fri Apr 10 01:11:55 +0000 2020',\n",
       "  'text': 'RT @Berkarya_Info: Kuatkan ketahanan pangan, jauhi desa digital (sasaran ekspansi kapitalis berbekal big data).  Produksi barang yang tidak…'},\n",
       " {'created_at': 'Fri Apr 10 01:11:58 +0000 2020',\n",
       "  'text': \"It's called Science.........You start with a theory and you prove, disprove, or modify your theory as you do your r… https://t.co/JjeDR6Rqkf\"},\n",
       " {'created_at': 'Fri Apr 10 01:12:01 +0000 2020',\n",
       "  'text': '@Ana_Squared Love me some Python :) Packaging is definitely an unsolved problem for the uninitiated.'},\n",
       " {'created_at': 'Fri Apr 10 01:12:09 +0000 2020',\n",
       "  'text': 'scikit-learn Cookbook - Second Edition: Over 80 recipes for machine learning in Python with scikit-learn… https://t.co/YOsReTGDsJ'},\n",
       " {'created_at': 'Fri Apr 10 01:12:09 +0000 2020',\n",
       "  'text': 'The Python Language Reference: Release 3.6.4 https://t.co/A5XXmqk3k5  #python #ad'},\n",
       " {'created_at': 'Fri Apr 10 01:12:11 +0000 2020',\n",
       "  'text': 'RT @DD_FaFa_: R for Data Science: Import, Tidy, Transform, Visualize, and Model Data https://t.co/CTNQNjP8M9 #DataScience'},\n",
       " {'created_at': 'Fri Apr 10 01:12:14 +0000 2020',\n",
       "  'text': 'RT @GIS_DOG: @DThompsonDev Have to get my friend @GinoPronos some motivation!  He’s learning how to code in python and C right now in a #Li…'},\n",
       " {'created_at': 'Fri Apr 10 01:12:16 +0000 2020',\n",
       "  'text': '@reddeerlee This might be a good time for City if Red Deer to work on an economic renewal plan with businesses. Sta… https://t.co/I2nrl05m0T'},\n",
       " {'created_at': 'Fri Apr 10 01:12:16 +0000 2020',\n",
       "  'text': \"'The U.S.reiterates the need for complete transparency, timely sharing of public health data, information. The most… https://t.co/onx70OVlIx\"},\n",
       " {'created_at': 'Fri Apr 10 01:12:23 +0000 2020',\n",
       "  'text': 'RT @GIS_DOG: @DThompsonDev Have to get my friend @GinoPronos some motivation!  He’s learning how to code in python and C right now in a #Li…'},\n",
       " {'created_at': 'Fri Apr 10 01:12:28 +0000 2020',\n",
       "  'text': 'RT @srmduke87: @ALT_uscis Data and science will eventually carry the day'},\n",
       " {'created_at': 'Fri Apr 10 01:12:31 +0000 2020',\n",
       "  'text': '全てはpythonで型チェックできないのが元凶なんだよな'},\n",
       " {'created_at': 'Fri Apr 10 01:12:31 +0000 2020',\n",
       "  'text': \"RT @pyGEDI: pyGEDI: New Python Package for analyzing @GEDI_Knights data from NASA's Global Ecosystem Dynamics Investigation.\\n\\nhttps://t.co/…\"},\n",
       " {'created_at': 'Fri Apr 10 01:12:37 +0000 2020',\n",
       "  'text': \"RT @couponfree01: Udemy Free Discount - Webpack 2: The Complete Developer's Guide #udemycoupon https://t.co/1tFDdJiqZl\\n\\n#webdevelopment #ja…\"},\n",
       " {'created_at': 'Fri Apr 10 01:12:38 +0000 2020',\n",
       "  'text': 'RT @juliecollins123: Evet sayın müminler, biliyorum bizi günahınız kadar sevmezsiniz ama maalesef çözüm yine #Israel’den geliyor..😃😃🇮🇱🇮🇱🇮🇱'},\n",
       " {'created_at': 'Fri Apr 10 01:12:39 +0000 2020',\n",
       "  'text': 'RT @antgrasso: Quantum science could have significant implications for national security. By taking simple, pragmatic steps today, governme…'},\n",
       " {'created_at': 'Fri Apr 10 01:12:52 +0000 2020',\n",
       "  'text': \"RT @ResistanceRules: Porter's report shows the Trump administration was not simply ill-prepared for the coming pandemic, but actively makin…\"},\n",
       " {'created_at': 'Fri Apr 10 01:12:57 +0000 2020',\n",
       "  'text': 'RT @gp_pulipaka: Cheat Sheets: #Python, #DataScience, R, and More. #BigData #Analytics #IoT #IIoT #PyTorch #RStats #TensorFlow #JavaScript…'},\n",
       " {'created_at': 'Fri Apr 10 01:12:57 +0000 2020',\n",
       "  'text': 'RT @DataCamp: Staying Home More? Why not learn a new skill and boost your career. \\nTry Our Free Intro to SQL, Today!  Learn by doing intera…'},\n",
       " {'created_at': 'Fri Apr 10 01:12:57 +0000 2020',\n",
       "  'text': 'RT @GrimmGreen: how do we have to state AGs @MassAGO and @AGIowa with such DRASTICALLY differing views on #Vaping ?  Do they not have acces…'},\n",
       " {'created_at': 'Fri Apr 10 01:12:59 +0000 2020',\n",
       "  'text': 'Using Data Science to Advance Educational Tools for Young Children: Fifth Annual Data Science Bowl Announces Winner… https://t.co/5Zn3ZeUpym'},\n",
       " {'created_at': 'Fri Apr 10 01:13:00 +0000 2020',\n",
       "  'text': 'RT @zeldia123: Learn these mini tricks to spice up your #python #data analysis🎩\\n🦄Combine least frequent categories\\n🐥Zip to iterate list ele…'},\n",
       " {'created_at': 'Fri Apr 10 01:13:05 +0000 2020',\n",
       "  'text': 'RT @zeldia123: Learn these mini tricks to spice up your #python #data analysis🎩\\n🦄Combine least frequent categories\\n🐥Zip to iterate list ele…'},\n",
       " {'created_at': 'Fri Apr 10 01:13:06 +0000 2020',\n",
       "  'text': 'Nas dúvidas do layout ainda.. mas vai sair o fute filosofico do MONTY PYTHON.\\n\\n#futeboldebotao https://t.co/8R5ChVvT9a'},\n",
       " {'created_at': 'Fri Apr 10 01:13:11 +0000 2020',\n",
       "  'text': '@diabovestepraga eu peguei um\\nvi metade a um tempinho \\nmas devo largar pq vou largar python pra ver js e java(só vo… https://t.co/mz62cyTGhy'},\n",
       " {'created_at': 'Fri Apr 10 01:13:15 +0000 2020',\n",
       "  'text': 'For those taking part in #30DaysOfPython, I hope you had fun tackling the credit card validator project!\\n\\nOver the… https://t.co/MDK7mNHYEv'},\n",
       " {'created_at': 'Fri Apr 10 01:13:27 +0000 2020',\n",
       "  'text': 'RT @zeldia123: Learn these mini tricks to spice up your #python #data analysis🎩\\n🦄Combine least frequent categories\\n🐥Zip to iterate list ele…'},\n",
       " {'created_at': 'Fri Apr 10 01:13:29 +0000 2020',\n",
       "  'text': 'RT @ProfessorAMuse: A whispered hero &amp; call to action is connecting us to navigate thru &amp; after #COVIDー19 \\n\\n\\U0001fa7aTele-medicine\\n📚Tele-education…'},\n",
       " {'created_at': 'Fri Apr 10 01:13:30 +0000 2020',\n",
       "  'text': 'Solo he visto la mitad!! 😮📺 📼 \\nTop 20 movies about Artificial Intelligence and Big Data. by @benthecoder1 in… https://t.co/zqsYfAsqqE'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando um dataset com dados retornados do MongoDB\n",
    "dataset = [{\"created_at\": item[\"created_at\"], \"text\": item[\"text\"],} for item in col.find()]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.1'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando o módulo Pandas para trabalhar com datasets em Python\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe a partir do dataset \n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Thu Apr 09 23:57:17 +0000 2020</td>\n",
       "      <td>@DrSCoffin perpetuated recently by the big jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Thu Apr 09 23:57:18 +0000 2020</td>\n",
       "      <td>RT @gp_pulipaka: #TensorFlow 2.0 and #AI Make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Thu Apr 09 23:57:18 +0000 2020</td>\n",
       "      <td>@Tzefira_Neviah Python is a great start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fri Apr 10 01:10:31 +0000 2020</td>\n",
       "      <td>RT @antgrasso: Quantum science could have sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fri Apr 10 01:10:32 +0000 2020</td>\n",
       "      <td>Data Science -Project Leader – The Aerospace C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Fri Apr 10 01:10:49 +0000 2020</td>\n",
       "      <td>You can dislike firearms or The Post Millenial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Fri Apr 10 01:10:58 +0000 2020</td>\n",
       "      <td>RT @MJA_Editor: Agree. And publish it. Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Fri Apr 10 01:10:59 +0000 2020</td>\n",
       "      <td>@realDonaldTrump stop taking advice from Bill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Fri Apr 10 01:11:05 +0000 2020</td>\n",
       "      <td>Ignore Errors when Reading Wifis on macOS http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Fri Apr 10 01:11:06 +0000 2020</td>\n",
       "      <td>Sick python burn. “I would hate to be a bank a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Fri Apr 10 01:11:13 +0000 2020</td>\n",
       "      <td>Programando em Python e bate aquela saudade do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Fri Apr 10 01:11:13 +0000 2020</td>\n",
       "      <td>RT @Cris_noticias: Según data preliminar un tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Fri Apr 10 01:11:17 +0000 2020</td>\n",
       "      <td>RT @couponfree01: Udemy Free Discount - Webpac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Fri Apr 10 01:11:22 +0000 2020</td>\n",
       "      <td>RT @fb_vinid: Our new paper is finally online ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Fri Apr 10 01:11:22 +0000 2020</td>\n",
       "      <td>RT @arteagamassieu: Israeli COVID-19 treatment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Fri Apr 10 01:11:23 +0000 2020</td>\n",
       "      <td>@ALT_uscis Data and science will eventually ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Fri Apr 10 01:11:25 +0000 2020</td>\n",
       "      <td>RT @StevenKirchner: Open Data Science Conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Fri Apr 10 01:11:29 +0000 2020</td>\n",
       "      <td>RT @Berkarya_Info: Kuatkan ketahanan pangan, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Fri Apr 10 01:11:47 +0000 2020</td>\n",
       "      <td>RT @adlightner: Deciding to leave earlier than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Fri Apr 10 01:11:50 +0000 2020</td>\n",
       "      <td>RT @pyGEDI: pyGEDI: New Python Package for ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Fri Apr 10 01:11:53 +0000 2020</td>\n",
       "      <td>@dailyremarx Yes, I often wish I still had an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Fri Apr 10 01:11:55 +0000 2020</td>\n",
       "      <td>RT @treehouse: Enroll in Techdegree: https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Fri Apr 10 01:11:55 +0000 2020</td>\n",
       "      <td>RT @Berkarya_Info: Kuatkan ketahanan pangan, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Fri Apr 10 01:11:58 +0000 2020</td>\n",
       "      <td>It's called Science.........You start with a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Fri Apr 10 01:12:01 +0000 2020</td>\n",
       "      <td>@Ana_Squared Love me some Python :) Packaging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Fri Apr 10 01:12:09 +0000 2020</td>\n",
       "      <td>scikit-learn Cookbook - Second Edition: Over 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Fri Apr 10 01:12:09 +0000 2020</td>\n",
       "      <td>The Python Language Reference: Release 3.6.4 h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Fri Apr 10 01:12:11 +0000 2020</td>\n",
       "      <td>RT @DD_FaFa_: R for Data Science: Import, Tidy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Fri Apr 10 01:12:14 +0000 2020</td>\n",
       "      <td>RT @GIS_DOG: @DThompsonDev Have to get my frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Fri Apr 10 01:12:16 +0000 2020</td>\n",
       "      <td>@reddeerlee This might be a good time for City...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Fri Apr 10 01:12:16 +0000 2020</td>\n",
       "      <td>'The U.S.reiterates the need for complete tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Fri Apr 10 01:12:23 +0000 2020</td>\n",
       "      <td>RT @GIS_DOG: @DThompsonDev Have to get my frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Fri Apr 10 01:12:28 +0000 2020</td>\n",
       "      <td>RT @srmduke87: @ALT_uscis Data and science wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Fri Apr 10 01:12:31 +0000 2020</td>\n",
       "      <td>全てはpythonで型チェックできないのが元凶なんだよな</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Fri Apr 10 01:12:31 +0000 2020</td>\n",
       "      <td>RT @pyGEDI: pyGEDI: New Python Package for ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Fri Apr 10 01:12:37 +0000 2020</td>\n",
       "      <td>RT @couponfree01: Udemy Free Discount - Webpac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Fri Apr 10 01:12:38 +0000 2020</td>\n",
       "      <td>RT @juliecollins123: Evet sayın müminler, bili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Fri Apr 10 01:12:39 +0000 2020</td>\n",
       "      <td>RT @antgrasso: Quantum science could have sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Fri Apr 10 01:12:52 +0000 2020</td>\n",
       "      <td>RT @ResistanceRules: Porter's report shows the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Fri Apr 10 01:12:57 +0000 2020</td>\n",
       "      <td>RT @gp_pulipaka: Cheat Sheets: #Python, #DataS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Fri Apr 10 01:12:57 +0000 2020</td>\n",
       "      <td>RT @DataCamp: Staying Home More? Why not learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Fri Apr 10 01:12:57 +0000 2020</td>\n",
       "      <td>RT @GrimmGreen: how do we have to state AGs @M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Fri Apr 10 01:12:59 +0000 2020</td>\n",
       "      <td>Using Data Science to Advance Educational Tool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Fri Apr 10 01:13:00 +0000 2020</td>\n",
       "      <td>RT @zeldia123: Learn these mini tricks to spic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Fri Apr 10 01:13:05 +0000 2020</td>\n",
       "      <td>RT @zeldia123: Learn these mini tricks to spic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Fri Apr 10 01:13:06 +0000 2020</td>\n",
       "      <td>Nas dúvidas do layout ainda.. mas vai sair o f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Fri Apr 10 01:13:11 +0000 2020</td>\n",
       "      <td>@diabovestepraga eu peguei um\\nvi metade a um ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Fri Apr 10 01:13:15 +0000 2020</td>\n",
       "      <td>For those taking part in #30DaysOfPython, I ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Fri Apr 10 01:13:27 +0000 2020</td>\n",
       "      <td>RT @zeldia123: Learn these mini tricks to spic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Fri Apr 10 01:13:29 +0000 2020</td>\n",
       "      <td>RT @ProfessorAMuse: A whispered hero &amp;amp; cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>Fri Apr 10 01:13:30 +0000 2020</td>\n",
       "      <td>Solo he visto la mitad!! 😮📺 📼 \\nTop 20 movies ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Thu Apr 09 23:57:17 +0000 2020   \n",
       "1   Thu Apr 09 23:57:18 +0000 2020   \n",
       "2   Thu Apr 09 23:57:18 +0000 2020   \n",
       "3   Fri Apr 10 01:10:31 +0000 2020   \n",
       "4   Fri Apr 10 01:10:32 +0000 2020   \n",
       "5   Fri Apr 10 01:10:49 +0000 2020   \n",
       "6   Fri Apr 10 01:10:58 +0000 2020   \n",
       "7   Fri Apr 10 01:10:59 +0000 2020   \n",
       "8   Fri Apr 10 01:11:05 +0000 2020   \n",
       "9   Fri Apr 10 01:11:06 +0000 2020   \n",
       "10  Fri Apr 10 01:11:13 +0000 2020   \n",
       "11  Fri Apr 10 01:11:13 +0000 2020   \n",
       "12  Fri Apr 10 01:11:17 +0000 2020   \n",
       "13  Fri Apr 10 01:11:22 +0000 2020   \n",
       "14  Fri Apr 10 01:11:22 +0000 2020   \n",
       "15  Fri Apr 10 01:11:23 +0000 2020   \n",
       "16  Fri Apr 10 01:11:25 +0000 2020   \n",
       "17  Fri Apr 10 01:11:29 +0000 2020   \n",
       "18  Fri Apr 10 01:11:47 +0000 2020   \n",
       "19  Fri Apr 10 01:11:50 +0000 2020   \n",
       "20  Fri Apr 10 01:11:53 +0000 2020   \n",
       "21  Fri Apr 10 01:11:55 +0000 2020   \n",
       "22  Fri Apr 10 01:11:55 +0000 2020   \n",
       "23  Fri Apr 10 01:11:58 +0000 2020   \n",
       "24  Fri Apr 10 01:12:01 +0000 2020   \n",
       "25  Fri Apr 10 01:12:09 +0000 2020   \n",
       "26  Fri Apr 10 01:12:09 +0000 2020   \n",
       "27  Fri Apr 10 01:12:11 +0000 2020   \n",
       "28  Fri Apr 10 01:12:14 +0000 2020   \n",
       "29  Fri Apr 10 01:12:16 +0000 2020   \n",
       "30  Fri Apr 10 01:12:16 +0000 2020   \n",
       "31  Fri Apr 10 01:12:23 +0000 2020   \n",
       "32  Fri Apr 10 01:12:28 +0000 2020   \n",
       "33  Fri Apr 10 01:12:31 +0000 2020   \n",
       "34  Fri Apr 10 01:12:31 +0000 2020   \n",
       "35  Fri Apr 10 01:12:37 +0000 2020   \n",
       "36  Fri Apr 10 01:12:38 +0000 2020   \n",
       "37  Fri Apr 10 01:12:39 +0000 2020   \n",
       "38  Fri Apr 10 01:12:52 +0000 2020   \n",
       "39  Fri Apr 10 01:12:57 +0000 2020   \n",
       "40  Fri Apr 10 01:12:57 +0000 2020   \n",
       "41  Fri Apr 10 01:12:57 +0000 2020   \n",
       "42  Fri Apr 10 01:12:59 +0000 2020   \n",
       "43  Fri Apr 10 01:13:00 +0000 2020   \n",
       "44  Fri Apr 10 01:13:05 +0000 2020   \n",
       "45  Fri Apr 10 01:13:06 +0000 2020   \n",
       "46  Fri Apr 10 01:13:11 +0000 2020   \n",
       "47  Fri Apr 10 01:13:15 +0000 2020   \n",
       "48  Fri Apr 10 01:13:27 +0000 2020   \n",
       "49  Fri Apr 10 01:13:29 +0000 2020   \n",
       "50  Fri Apr 10 01:13:30 +0000 2020   \n",
       "\n",
       "                                                 text  \n",
       "0   @DrSCoffin perpetuated recently by the big jou...  \n",
       "1   RT @gp_pulipaka: #TensorFlow 2.0 and #AI Make ...  \n",
       "2             @Tzefira_Neviah Python is a great start  \n",
       "3   RT @antgrasso: Quantum science could have sign...  \n",
       "4   Data Science -Project Leader – The Aerospace C...  \n",
       "5   You can dislike firearms or The Post Millenial...  \n",
       "6   RT @MJA_Editor: Agree. And publish it. Austral...  \n",
       "7   @realDonaldTrump stop taking advice from Bill ...  \n",
       "8   Ignore Errors when Reading Wifis on macOS http...  \n",
       "9   Sick python burn. “I would hate to be a bank a...  \n",
       "10  Programando em Python e bate aquela saudade do...  \n",
       "11  RT @Cris_noticias: Según data preliminar un tr...  \n",
       "12  RT @couponfree01: Udemy Free Discount - Webpac...  \n",
       "13  RT @fb_vinid: Our new paper is finally online ...  \n",
       "14  RT @arteagamassieu: Israeli COVID-19 treatment...  \n",
       "15  @ALT_uscis Data and science will eventually ca...  \n",
       "16  RT @StevenKirchner: Open Data Science Conferen...  \n",
       "17  RT @Berkarya_Info: Kuatkan ketahanan pangan, j...  \n",
       "18  RT @adlightner: Deciding to leave earlier than...  \n",
       "19  RT @pyGEDI: pyGEDI: New Python Package for ana...  \n",
       "20  @dailyremarx Yes, I often wish I still had an ...  \n",
       "21  RT @treehouse: Enroll in Techdegree: https://t...  \n",
       "22  RT @Berkarya_Info: Kuatkan ketahanan pangan, j...  \n",
       "23  It's called Science.........You start with a t...  \n",
       "24  @Ana_Squared Love me some Python :) Packaging ...  \n",
       "25  scikit-learn Cookbook - Second Edition: Over 8...  \n",
       "26  The Python Language Reference: Release 3.6.4 h...  \n",
       "27  RT @DD_FaFa_: R for Data Science: Import, Tidy...  \n",
       "28  RT @GIS_DOG: @DThompsonDev Have to get my frie...  \n",
       "29  @reddeerlee This might be a good time for City...  \n",
       "30  'The U.S.reiterates the need for complete tran...  \n",
       "31  RT @GIS_DOG: @DThompsonDev Have to get my frie...  \n",
       "32  RT @srmduke87: @ALT_uscis Data and science wil...  \n",
       "33                       全てはpythonで型チェックできないのが元凶なんだよな  \n",
       "34  RT @pyGEDI: pyGEDI: New Python Package for ana...  \n",
       "35  RT @couponfree01: Udemy Free Discount - Webpac...  \n",
       "36  RT @juliecollins123: Evet sayın müminler, bili...  \n",
       "37  RT @antgrasso: Quantum science could have sign...  \n",
       "38  RT @ResistanceRules: Porter's report shows the...  \n",
       "39  RT @gp_pulipaka: Cheat Sheets: #Python, #DataS...  \n",
       "40  RT @DataCamp: Staying Home More? Why not learn...  \n",
       "41  RT @GrimmGreen: how do we have to state AGs @M...  \n",
       "42  Using Data Science to Advance Educational Tool...  \n",
       "43  RT @zeldia123: Learn these mini tricks to spic...  \n",
       "44  RT @zeldia123: Learn these mini tricks to spic...  \n",
       "45  Nas dúvidas do layout ainda.. mas vai sair o f...  \n",
       "46  @diabovestepraga eu peguei um\\nvi metade a um ...  \n",
       "47  For those taking part in #30DaysOfPython, I ho...  \n",
       "48  RT @zeldia123: Learn these mini tricks to spic...  \n",
       "49  RT @ProfessorAMuse: A whispered hero &amp; cal...  \n",
       "50  Solo he visto la mitad!! 😮📺 📼 \\nTop 20 movies ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo o dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o módulo Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método CountVectorizer para criar uma matriz de documentos\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rt</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>co</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>to</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>python</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>data</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>and</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>for</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>in</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>science</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>have</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>do</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>learn</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>you</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>your</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>by</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>an</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>with</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>from</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>taking</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>is</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>pygedi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>learning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>big</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>as</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>get</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>ele</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>list</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>least</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>up</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>iterate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>it</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>categories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>tricks</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>zeldia123</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>how</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>combine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>complete</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>he</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>today</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>frequent</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>free</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>datascience</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>some</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>these</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>spice</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>not</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>be</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  count\n",
       "0            rt     29\n",
       "1            co     26\n",
       "2         https     26\n",
       "3            to     25\n",
       "4           the     22\n",
       "5        python     21\n",
       "6          data     21\n",
       "7           and     19\n",
       "8           for     13\n",
       "9            in     10\n",
       "10      science     10\n",
       "11         have      8\n",
       "12           do      7\n",
       "13        learn      7\n",
       "14          you      7\n",
       "15         your      7\n",
       "16           by      6\n",
       "17           an      5\n",
       "18         with      5\n",
       "19         from      4\n",
       "20       taking      4\n",
       "21           is      4\n",
       "22       pygedi      4\n",
       "23     learning      4\n",
       "24          big      4\n",
       "25           as      4\n",
       "26          get      4\n",
       "27          new      4\n",
       "28          ele      3\n",
       "29         list      3\n",
       "30        least      3\n",
       "31           up      3\n",
       "32      iterate      3\n",
       "33           it      3\n",
       "34   categories      3\n",
       "35       tricks      3\n",
       "36    zeldia123      3\n",
       "37          how      3\n",
       "38      combine      3\n",
       "39     complete      3\n",
       "40           he      3\n",
       "41        today      3\n",
       "42     frequent      3\n",
       "43         free      3\n",
       "44  datascience      3\n",
       "45         some      3\n",
       "46        these      3\n",
       "47        spice      3\n",
       "48          not      3\n",
       "49           be      3"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contando o número de ocorrências das principais palavras em nosso dataset\n",
    "word_count = pd.DataFrame(cv.get_feature_names(), columns=[\"word\"])\n",
    "word_count[\"count\"] = count_matrix.sum(axis=0).tolist()[0]\n",
    "word_count = word_count.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "word_count[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=\"http://facebook.com/dsacademybr\">facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
